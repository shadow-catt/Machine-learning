{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS4023 Machine Learning : Ensemble Learning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise, you'll explore different ensemble methods and how does ensemble improves the performance of a machine learning model. There are three parts in this exercise:\n",
    "1. Simple ensemble strategy: majority voting\n",
    "2. Bagging Method\n",
    "3. Boosting Method: Adaboost\n",
    "\n",
    "The dataset we use for this exercise is a cancer dataset with 699 instances and a total number of 9 features labeled in either benign or malignant classes (0 for benign, 1 for malignant). The dataset only contains numeric values and has been normalized.\n",
    "\n",
    "Many methods will use random generator, e.g., train-test split, decision tree model, bagging boostramp sample generation, therefore, we can set the seed to a fixed number in order to achieve same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.379749</td>\n",
       "      <td>0.237164</td>\n",
       "      <td>0.245271</td>\n",
       "      <td>0.200763</td>\n",
       "      <td>0.246225</td>\n",
       "      <td>0.346352</td>\n",
       "      <td>0.270863</td>\n",
       "      <td>0.207439</td>\n",
       "      <td>0.065490</td>\n",
       "      <td>0.344778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.312860</td>\n",
       "      <td>0.339051</td>\n",
       "      <td>0.330213</td>\n",
       "      <td>0.317264</td>\n",
       "      <td>0.246033</td>\n",
       "      <td>0.364071</td>\n",
       "      <td>0.270929</td>\n",
       "      <td>0.339293</td>\n",
       "      <td>0.190564</td>\n",
       "      <td>0.475636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "count       699.000000               699.000000                699.000000   \n",
       "mean          0.379749                 0.237164                  0.245271   \n",
       "std           0.312860                 0.339051                  0.330213   \n",
       "min           0.000000                 0.000000                  0.000000   \n",
       "25%           0.111111                 0.000000                  0.000000   \n",
       "50%           0.333333                 0.000000                  0.000000   \n",
       "75%           0.555556                 0.444444                  0.444444   \n",
       "max           1.000000                 1.000000                  1.000000   \n",
       "\n",
       "       Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "count         699.000000                   699.000000   699.000000   \n",
       "mean            0.200763                     0.246225     0.346352   \n",
       "std             0.317264                     0.246033     0.364071   \n",
       "min             0.000000                     0.000000     0.000000   \n",
       "25%             0.000000                     0.111111     0.100000   \n",
       "50%             0.000000                     0.111111     0.100000   \n",
       "75%             0.333333                     0.333333     0.500000   \n",
       "max             1.000000                     1.000000     1.000000   \n",
       "\n",
       "       Bland Chromatin  Normal Nucleoli     Mitoses       Class  \n",
       "count       699.000000       699.000000  699.000000  699.000000  \n",
       "mean          0.270863         0.207439    0.065490    0.344778  \n",
       "std           0.270929         0.339293    0.190564    0.475636  \n",
       "min           0.000000         0.000000    0.000000    0.000000  \n",
       "25%           0.111111         0.000000    0.000000    0.000000  \n",
       "50%           0.222222         0.000000    0.000000    0.000000  \n",
       "75%           0.444444         0.333333    0.000000    1.000000  \n",
       "max           1.000000         1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "data = pd.read_csv(\"cancer_normalized.csv\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0         0.444444                 0.000000                  0.000000   \n",
       "1         0.444444                 0.333333                  0.333333   \n",
       "2         0.222222                 0.000000                  0.000000   \n",
       "3         0.555556                 0.777778                  0.777778   \n",
       "4         0.333333                 0.000000                  0.000000   \n",
       "\n",
       "   Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "0           0.000000                     0.111111          0.1   \n",
       "1           0.444444                     0.666667          1.0   \n",
       "2           0.000000                     0.111111          0.2   \n",
       "3           0.000000                     0.222222          0.4   \n",
       "4           0.222222                     0.111111          0.1   \n",
       "\n",
       "   Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0         0.222222         0.000000      0.0    0.0  \n",
       "1         0.222222         0.111111      0.0    0.0  \n",
       "2         0.222222         0.000000      0.0    0.0  \n",
       "3         0.222222         0.666667      0.0    0.0  \n",
       "4         0.222222         0.000000      0.0    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Simple Ensemble Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will look at a simple ensemble technique for classification: majority voting. In this method, multiple models are used to make predictions for each data instance. The predictions by each model are considered as a **vote**. The prediction which we get from the majority of the models are used as the final prediction.\n",
    "\n",
    "Scikit-Learn provides us with some handy functions that we can use to accomplish this.\n",
    "- The ``VotingClassifier`` takes in a list of different estimators as arguments and a voting method. The ``hard`` voting method uses the predicted labels and a majority rules system, while the ``soft`` voting method predicts a label based on the sum of the predicted probabilities.\n",
    "\n",
    "Here, we use three models, *Decision Tree*, *SVM* and *LogisticRegression*, for voting and adopt 10-fold cross validation. Report the mean accuracy of **individual classifiers and the ensemble by applying the majority voting strategy (**hard voting**).** Compare the performance. \n",
    "- Note: For DecisionTreeClassifier() implementation, the features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "# cross validation library\n",
    "from sklearn.model_selection import cross_val_score\n",
    "seed = 7\n",
    "\n",
    "# your implementation here\n",
    "# model for three\n",
    "decision_tree_cls = DecisionTreeClassifier(random_state=seed)\n",
    "logistic_reg_cls = LogisticRegression(random_state=seed)\n",
    "svc_cls = SVC(random_state=seed)\n",
    "\n",
    "# voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('log_clf', LogisticRegression(random_state=seed)),\n",
    "    ('svm_clf', SVC(random_state=seed)),\n",
    "    ('dt_clf', DecisionTreeClassifier(random_state=seed))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(699,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "display(x.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean accuarcy for ten fold(represented as cv)\n",
    "ten_tree_acc = cross_val_score(decision_tree_cls,x,y,cv=10)\n",
    "ten_logist_acc = cross_val_score(logistic_reg_cls,x,y,cv=10)\n",
    "ten_svc_acc = cross_val_score(svc_cls,x,y,cv=10)\n",
    "ten_vote_acc = cross_val_score(voting_clf,x,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean tree accuarcy:  0.9485093167701864\n",
      "Mean logist accuarcy:  0.9628571428571429\n",
      "Mean svc accuarcy:  0.9685507246376812\n",
      "Mean vote accuarcy:  0.9642650103519671\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean tree accuarcy: \", ten_tree_acc.mean())\n",
    "print(\"Mean logist accuarcy: \",ten_logist_acc.mean())\n",
    "print(\"Mean svc accuarcy: \",ten_svc_acc.mean())\n",
    "print(\"Mean vote accuarcy: \",ten_vote_acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will explore the bagging method by using decision tree as the base learning algorithm. Scikit-Learn provides us a module of ``BaggingClassifier``, we can provide the base learning model and the number of estimation models. Try to set the number of estimators to 100 and report the mean accuracy of the ensemble using 10-fold cross validation. Compare the performance with a single decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "num_trees = 100\n",
    "\n",
    "# using baggin classifier\n",
    "bag_clf = BaggingClassifier(decision_tree_cls,\n",
    "                            n_estimators = num_trees,\n",
    "                            bootstrap = True,\n",
    "                            n_jobs = -1,\n",
    "                            oob_score = True,\n",
    "                            random_state = seed)\n",
    "ten_bagging_tree_acc = cross_val_score(bag_clf,x,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean tree accuarcy:  0.9485093167701864\n",
      "Mean bagging tree accuarcy:  0.9557142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean tree accuarcy: \", ten_tree_acc.mean())\n",
    "print(\"Mean bagging tree accuarcy: \", ten_bagging_tree_acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialized a 10-fold cross-validation fold. After that, we instantiated a Decision Tree Classifier with 100 trees and wrapped it in a Bagging-based Ensemble. The accuracy improved to 95.85%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn also provides access to the ``RandomForestClassifier``, which is a modification of the decision tree classification. Use random forest model and report the mean accuracy by using 10-folds cross-validation. Number of trees set to 100.\n",
    "\n",
    "**Compare the performance of RandomForestClassifier with bagged decision tree and give the analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest_cls = RandomForestClassifier(random_state = seed)\n",
    "ten_random_forest_acc = cross_val_score(random_forest_cls,x,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean bagging_random_forest accuarcy:  0.9671428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean bagging_random_forest accuarcy: \", ten_random_forest_acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison and analysis**:\n",
    "\n",
    "The preformance of the **random forest** is better than the preformance of the **bagged decision tree**. Bagged decision tree generate a lot of tree according to the bootstrap sample. Based on it, when constructing each decision tree, the random forest will randomly select some feature subsets from all the features. Each time the tree is split, the optimal one will be selected from these features. Many this is the reason why it have better preformance than the bagged decision tree. These to method both have robustness, but the **bagged decision tree** more tend to the sample and the **random forest** more tend to sample as well as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you use AdaBoost classification by boosting the ``decision stump``(**one-level decision tree**).Try to set the number of rounds to 100 and report the performance of the ensemble. Compare the performance with a single decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_boost_tree_cls = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=1, \n",
    "                                                                                andom_state = seed),\n",
    "                                       n_estimators = 100,\n",
    "                                       random_state = seed)\n",
    "ten_ada_boost_tree_acc = cross_val_score(ada_boost_tree_cls,x,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean tree accuarcy:  0.9485093167701864\n",
      "Mean Adaboost tree accuarcy:  0.9585507246376814\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean tree accuarcy: \", ten_tree_acc.mean())\n",
    "print(\"Mean Adaboost tree accuarcy: \", ten_ada_boost_tree_acc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
